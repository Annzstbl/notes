# An overview of hyperspectral image feature extraction, classification methods and the methods based on small samples

高光谱的光谱谱段之间存在较强的相关性，这对于网络输入是不好的。

小数据集



## 光谱信息提取

PCA 主成分信息提取

​	缺点：然而，当使用PCA时，有时图像质量并不会随着主成分的减少而稳定下降。（However, when PCA is used, sometimes the image quality does not decline steadily with the decrease of principal component.）

MNF 最小噪声分数

​	通过引入信号方差和噪声方差来分离噪声，提取特征。

SMNF, a segmented maximum noise fraction 

​	基于MNF

ICA

​	PCA和MNF会损失一些主成分，ICA方法的目标是找到使数据独立的最大映射，可以保留小类别信息（非主成分）

LDA

​	小样本不好用

LFDA

Non-parametric Weighted Feature Extraction (NWFE)

## 空间信息提取

morphological profiles (MP)

gray level cooccurrence matrix (GLCM)



# Class-wise Graph Embedding-Based Active Learning for Hyperspectral Image Classification

提出一种 针对HSI分类任务，基于类感知图神经网络(GCN)的 主动学习(AL)方法

该方法首先利用已标注的数据训练一个分类器(classifier),期待该分类器去推理已标注数据和未标注数据的特征区别。

接下类，把已标注数据按类别分类成各类数据和未标注数据。

之后，把这些数据（经过分类器的）作为节点输入到CGCN中。

CGTN通过最小化binary loss进行训练，推出标注节点和为标注节点间的不确定关系。

**这里是利用训练的结果作为未标注节点的不确定度的，所以可以理解为用训练的难度表示特征的独特性**

对不确定度较高的未标注节点，去查询该节点距离各标注节点的不确定关系，选取其中最小的不确定度作为度量，使其与阈值比较。

之后，反复重复该过程，来retrain网络。

## 结构

![image-20240306111916944](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240306111916944.png)

## AL方法

committee方法：多角度或多尺度模型对未标注数据测量其与标注数据的分歧，采用其最大分歧

representativeness方法：考虑未标注数据和标注数据的分布情况

uncertainty方法：考虑当前模型的最不确定性样本，为潜在的未标注样本？

## classification model

spectral-spatial residual network(SSRN)



# Dual-stream GNN fusion network for hyperspectral classification

一个用于图像分类的端到端的网络 DGFNet。

![image-20240304163636797](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240304163636797.png)

该网络将HSI图像裁切成子块，降低计算复杂度。这个子是以每个点作为中心去获取的。

空间分支（STCB）使用 图注意力网络(Graph Attention Network)捕获图像特征；同时使用图pooling和局部引导模型来提高效果。

光谱分支（SCDB）负责对不同波段的信息相关程度进行权重评估。

最后将光谱、空间和子块结构特征融合输入到分类分支。



## SFE

<img src="https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240304163740140.png" alt="image-20240304163740140" style="zoom:50%;" />

## STCB

分支的输入是一个子块的特征，例如$s1 \times s1\times C$，之后每一个像素作为一个节点构建图，即$s1\times s1$个节点。

之后图输入到PGAT和CNN guidance module两个小模块



PGAT旨在通过周围像素加强自身特征表达



#TODO pooling是在哪里做干什么，好像是对每一个subcube做一些特征的裁剪

## SDCB

输入和STCB一致，但是是在光谱维度处理

## 实验结果

![image-20240305150517156](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240305150517156.png)



# ELS2T: Efficient Lightweight Spectral–Spatial Transformer for Hyperspectral Image Classification

第一，引入Transformer，Global multiscale attention module(GMAM)全局多尺度注意力模型。

第二，构造Adaptive feature fusion module(AFFM)来考虑空间和光谱维度的不同重要性。

最后，为了减少计算复杂性，引入轻量化分离的self attention代替multihead self-attention。

## 结构

![image-20240305161159179](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240305161159179.png)

## GMAM

![image-20240306094744632](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240306094744632.png)

residual结构，通过MCAM增强特征

![image-20240306094825056](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240306094825056.png)

通过AvgPool和MaxPool提取特征的两组重要值，然后用卷积得到两组系数。

之后通过不同感受野的卷积结果，再乘系数得到

## AFFM

![image-20240306095105254](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240306095105254.png)

空间和光谱信息的融合

## $S^3A$ Separable Spatial-Spectral Self-Attention

![image-20240306095954719](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240306095954719.png)

I分支，直接用线性层得到一个得分(1, n)

K分支,(d,n)

用I分支的结果和K分支相乘结果得到得分图 (d,n)

把得分图和V用元素相乘得到结果

# From center to surrounding: An interactive learning framework for hyperspectral image classification

![image-20240306101803301](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240306101803301.png)

## Hyperspectral Image Classification With Multi-Attention Transformer and Adaptive Superpixel Segmentation-Based Active Learning

1.使用self attention获取全局特征

2.outlook-attention编码精细特征，和surrounding特征

3.基于superpixel segmentation的AL方法。

4.一个adaptive superpixel segmentation algorithm的方法生成为AL更好的限制

## 结构

![image-20240306160505805](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240306160505805.png)

# Multireceptive field: An adaptive path aggregation graph neural framework for hyperspectral image classification

不知道在说啥

# Transformer-Based Masked Autoencoder With Contrast

![image-20240306164435292](C:\Users\lth\AppData\Roaming\Typora\typora-user-images\image-20240306164435292.png)

加入了一个masked的模块，该模块屏蔽了subcube的部分区域，使Encoder去挖掘图像更深层次的信息。



# ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution

采用attention来分析global information，把其中的attention matrix的计算方式更改了，改成spectral correlation coefficient of the spectrum

进一步使用kernelizable attention 组成一个新的self-attention结构。

## 结构

![image-20240307100915027](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240307100915027.png)

## SSA

![image-20240307102446298](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240307102446298.png)

具有尺度和平移不变性

# ![image-20240307102512273](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240307102512273.png)Hyperspectral-to-image transform and CNN transfer learning enhancing soybean LCC estimation

应用类的文章

Hyperpsectral to image(HIT)



# DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for Hyperspectral Image Restoration

复原，主要是一些公式推导

# Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction

逐像素调整学习速率

提出Non-local Spectral Transformer

通过FFT提高stage interaction？

## Non-local Spectral Attention

![image-20240307112205538](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240307112205538.png)

## A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image Restoration

## A Trainable Spectral-Spatial Sparse Coding Model(T3SC)



# SiamBAG: Band Attention Grouping-Based Siamese Object Tracking Network for Hyperspectral Videos

结构

![image-20240313181232691](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240313181232691.png)



# Recent advances in object tracking using hyperspectral videos: a survey

## Band fusion or channel selection

![image-20240320102856122](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240320102856122.png)

![image-20240320102935643](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240320102935643.png)

![image-20240320103315635](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240320103315635.png)

## Feature Extraction

Spectral Angle Mapper

# SpectralDiff: A Generative Framework for Hyperspectral Image Classification WIth Diffusion Models

## Diffusion Models

基于得分的生成式模型

随机微分方程

去噪扩散概率模型

论文：Dif-fusion: Towards high color fidelity in infrared and visible image fusion with diffusion models,”

DiffusionDet: Diffusion model for object detection,

Denoising diffusion probabilistic models,

Image super-resolution via iterative refinement,

## 结构

![image-20240320163345749](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240320163345749.png)

## Spectral-Spatial Diffusion Module

作用是通过正向加噪声的过程和反向去噪的过程，模拟高光谱通道在潜在空间中的扩散来学习联合的潜在结构。

之后使用训练好的模型的中间输入作为特征，输入到后续分类网络

## Di-Fusion: Toward High Color Fidelity in Infrared and Visible Image Fusion With DIffusion Models

![image-20240320170057479](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240320170057479.png)

# Image Super-Resolution via Iterative Refinement

【17】Denoising diffusion probabilistic models.

【47】Deep unsupervised learning using nonequilibrium thermodynamics

![image-20240321155146759](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240321155146759.png)

q的过程是正向马尔科夫链的过程。

x是隐含的，在这里可能意味着超像素图像。？？？

逆过程是学习了一个$p_\theta(y_{t-1}|y_t, x)$的模型，通过该模型逐渐预测$y_0$

## 结构

SR3结构和DDPM论文中的U-net类似，做了和

Score-Based Generative Modeling through Stochastic Differential Equations

论文相似的改动，把原始的residual blocks换成了BigGAN中的residual blocks，把skip连接的尺度缩放了$\frac1{\sqrt{2}}$​。除此之外，增加了residual blocks的数量。

![image-20240327131459798](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240327131459798.png)

这是一个 16*16 -> 128 * 128 的超分辨任务结构

x是16*16通过插值得到的，y_t则是加噪声后的高斯噪声

## 训练

【6】Estimating Gradients for Waveform Generation.

使用一个分段分布$\gamma$？没看懂

$t \sim \{0,...,T\}$，T=2000

噪声生成的过程中，是需要进行t轮次的噪声叠加的。遵循【6】则可以有效的减少这个次数。

## DiffusionDet: Diffusion Model for Object Detection

噪声是框，去噪则是去掉非噪声框的过程

![image-20240327133357489](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240327133357489.png)

![image-20240327133347327](https://raw.githubusercontent.com/Annzstbl/image-host/main/img/image-20240327133347327.png)

cosine_beta_schedule
$$
timesteps=1000\\
x = 0,1,2,...,1000\\
s=0.008\\
alphas\_cumprod = cos(\frac{x/1000+s}{1+s}*0.5\pi)^2\in cos([\frac{0.008}{1.008},1]*0.5\pi)^2\rightarrow[nearly1->0]\\
alphas\_cumprod = \frac{alphas\_cumprod}{alphas\_cumprod[0]}\rightarrow[1->0]\\
$$
$\alpha_T = 0$,所以$\bar\alpha_T = 0$,其中$\bar\alpha = \prod_{i=0}^{t}\alpha_i$
$$
\beta_T = 1-\alpha_T\\
betas = 1-\frac{\bar\alpha[1:]}{\bar\alpha[:-1]}
$$

$$
\sigma = dse * \sqrt{(1-\frac {\alpha_t}{ \alpha_{t-1}})*(1-\alpha_{t-1})*(1-\alpha)}\\
c=\sqrt{1-\alpha_{t-1} - \sigma^2}
$$



# Denoising diffusion probabilistic models

这篇论文展示了使用diffusion probabilistic models(DDPM)进行高质量图像合成，DDPM是一类受非平衡热力徐启发的潜变量模型。通过训练一个 根据DDPM和去噪得分加权变分便捷？



## Diffusion

$$
p_\theta(x_0):=\int p_\theta(x_{0:T})dx_{1:T}
$$



## 概率生成式模型

构建一个概率函数$p(X)$​，利用该模型生成图像。

输入多个样本$x_1, x_2, ...x_m$，来训练获得$\theta$，这个参数就是$p(X)$的参数，可以是任何形式的。

但是对于$p(X)$来说，即使抽样也是非常困难的，所以通过隐变量来解决。

通过引入一个隐随机变量$Z$，然后根据$z$来生成$X$​。

即
$$
z\sim Z\\
x = f(z)
$$
最大似然概率模型：
$$
\arg\max_\theta log[p_\theta (x_1)p_\theta (x_2)...p_\theta (x_m)] \rightarrow \arg\max_\theta \sum_ilog[p_\theta(x_i)]
$$
所以最大似然概率模型，必须能够给出$p_\theta(x)$​

如果$f$可逆，则能够很容易算出，否则 
$$
p_\theta(x) = \int p_\theta(x,z)dz
$$
这个过程比较困难。

另一种方法是：
$$
p_\theta(x) = \frac{p_\theta(x,Z)}{p(Z|x)}
$$








# Denoising diffusion implicit models




$$
p(x|y)*p(y) = p(y|x) * p(x)
$$

$$
p(X) = \frac{p(X|Y)*p(Y)}{p(Y|X)}\\
p(X=x) = \frac{p(X=x|Y)*p(Y)}{p(Y|X = x)}
$$

