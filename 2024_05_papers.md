# A Closer Look at the Joint Training of Object Detection and Re-Identification in Multi-Object Tracking

## One-Shot MOT方法的训练

cost function定义
$$
C_{i,j} = \lambda_{cls} \cdot C_{cls}(p_i^{cls},g_j^{cls}) +\lambda_{reg}\cdot C_{reg}(p_i^{box},g_j^{box})
$$
正样本定义：
$$
S_{pos} = \{C_{i,j} < \phi(j), i \in S, j\in G
$$
最后的loss，是由所有地方的检测损失或分类损失，与正样本的定位损失和id损失构成
$$
L = \sum_{i \in S}L_{cls}(p_i^{cls}) + \sum_{i\in S_{pos}}L_{reg}(p_i^{box}) + \sum_{i\in S_{pos}}L_{REID}(p_i^{ID})
$$
在FairMOT中，一个GT只对应一个正样本，只有GT中心点才算正样本。

## Proposed 方法

$$
C_{i,j} = \lambda_{cls} \cdot C_{cls}(p_i^{cls},g_j^{cls}) +\lambda_{reg}\cdot C_{reg}(p_i^{box},g_j^{box}) + \lambda_{REID}\cdot C_{REID}(p_i^{ID}, g_j^{ID})
$$

效果提升有限，可能的原因是：训练开始ID的损失函数比较大，
$$
C_{i,j} = \lambda_{cls} \cdot C_{cls}(q_i^{ID}\cdot p_i^{cls},g_j^{cls}) +\lambda_{reg}\cdot C_{reg}(p_i^{box},g_j^{box})
$$

$$
q_i^{ID} = max(softmax(FC_{D\times N}(p_i^{ID})))
$$

不要求id特征与gt的id特征一致，转而要求ID特征明显的地方，分类损失占比要更大。
$$
C_re = \lambda_{L1} C_{L1}(pbox,gbox) + \lambda_{GIoU}C_{GIOU}(p,g)
$$



# Softmax Loss的缺点

1. 随着分类数目的增大，分类层的线性矩阵参数变大
2. 封闭集问题，学习到的特征是可分离的，但是开放集问题，特征没有足够的区分性

这个损失擅长学习类间的信息，采用了竞争机制。但是它忽略了非正确标签的差异，导致学习到的特征比较散。优化有：L-Softmax SM-Sofrmax AM-Softmax

参考文献：

Deng, Jiankang, et al. "Arcface: Additive angular margin loss for deep face recognition." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.
